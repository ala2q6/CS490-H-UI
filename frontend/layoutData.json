{
  "IMAGE1" : "https://cdn.discordapp.com/attachments/948804016320679946/963295901001064448/Untitled.png",
  "TITLE" : [
    "Classification of Star-Galaxy Images Using a Neural Network",
    "A UMKC Hack-A-Roo Project\n\nGarver and Arbuckle\n\nSpring 2022"
  ],
  "SPACER1" : "",
  "About Our Project..." : [
    "The goal of this project is to use a neural network to classify astronomical objects. The astronomy dataset we are using provides us with a list of images that can be categorized into either ‘galaxy’ or ‘star’. The images have been gathered manually with a telescope and smaller 64x64 pixel cutouts have been made, centered on identifiable stars or galaxies. More information about the dataset and its collection method can be found on Kaggle [1].",
    "You can view our presentation slides [here](https://docs.google.com/presentation/d/1WgB-1u6FW17lGXoPp3Tpn12H7kjhtRUEVdbLKCxRNDw/edit?usp=sharing). We talk more about our project in this short video, [here](https://umsystem.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=51f6598d-8d21-43bc-8932-ae75004c08a0)"
  ],
  "SPACER2" : "",
  "What We're Dealing With" : [
    "We originally intended to work on a project that would apply a neural network to playing candy crush. After much thought, research, and advice from our professor, we decided to reel in the scope of our project and work towards something more obtainable – classifying astronomical objects. We thought this project would be sufficiently challenging while providing us with an opportunity to work on real-world problems with common applications. Image classification is an important problem because it's constantly being applied in new fields for solving new problems."
  ],
  "SPACER3" :"",
  "About the Code..." : [
    "We decided to use a sequential model because we intended to have a linear stack of layers, so any benefit we would receive from a functional model would be forfeit.",
    "```\nmodel = Sequential()\nmodel.add(tf1.InputLayer(input_shape=inputShape))\nmodel.add(tf1.Rescaling(scale=1./255))\nmodel.add(tf1.Flatten())\nmodel.add(tf1.Dense(540, activation='relu'))\nmodel.add(tf1.Dense(1080, activation='relu'))\nmodel.add(tf1.BatchNormalization())\nmodel.add(tf1.Dense(640, activation='relu'))\nmodel.add(tf1.BatchNormalization())\nmodel.add(tf1.Dense(640, activation='relu'))\nmodel.add(tf1.BatchNormalization())\nmodel.add(tf1.Dense(340, activation='relu'))\nmodel.add(tf1.Dense(2, activation='softmax'))\n```",
    "We scale the input by 255 because that's the standard image pixel range. All hidden layers use the Rectified linear activation function because we thought this would most closely approximate the shape of the data. Batch normalization was used as an attempt to improve consistency over the execution time of the model.",
    "Below you can see our parameters for model compilation.",
    "```py\nmodel.compile(\n\tloss = 'categorical_crossentropy',\n\tmetrics = [tf.keras.metrics.Accuracy(), tf.keras.metrics.AUC()],\n\toptimizer = optimizers.Adam(learning_rate=0.005)\n)\n```",
    "In the above example you can see that we are using the categorical cross entropy loss function. We did this because...",
    "We evaluate our model using the keras accuracy metric and the AUC (area under curve) metric. We use the AUC metric because it gives us a more accurate evaluation of binary classifiers.",
    "Lastly, we use the Adam optimizer because of its efficiency and ability to handle large datasets.",
    "Here, you can see what parameters we specified for fitting the model.",
    "```py\nhistory = model.fit(\n\txTrain,\n\tyTrain,\n\tbatch_size = 64,\n\tepochs = 20,\n\tverbose = 1,\n\tvalidation_data = (xValid, yValid)\n)\n```",
    "The number of epochs has been limited and the batch size included to help prevent issues of over fitting."
  ],
  "SPACER4" : "",
  "The Results" : [
    "Unfortunately, we were unable to get our model working with a consistent accuracy above 20 percent before the deadline. Throughout our work during the Hackathon, we attempted both a traditional linear network and a convolutional neural network. The linear model gave us the provided accuracy, at its best getting to about 34 percent. Although we were able to get the convolutional network functioning, we were unable to get it to execute with any reasonable accuracy. We have a few ideas about where issues may have arisen. Foremost, we think that the difference between the individual data entries is small enough to warrant a much larger network, which is reinforced by our code references. Next, because we are analyzing images, we know a convolutional network will be more effective than a linear model. Finally, a better understanding of what the network is doing would allow us to more effectively choose our layers and increase accuracy."
  ],
  "IMAGE2" : "https://cdn.discordapp.com/attachments/948804016320679946/963296391919185930/unknown.png",
  "SPACER6" : "",
  "Credits Go To..." : [
    "1. [Star-Galaxy Dataset](https://www.kaggle.com/datasets/divyansh22/dummy-astronomy-data)",
    "2. [Code Reference](https://www.kaggle.com/code/akzenith/auc-score-0-95-resnet-from-scratch)",
    "3. [Code Reference](https://www.kaggle.com/code/paulinecalut/star-and-galaxy-pauline)",
    "4. [TensorFlow Documentation](https://www.tensorflow.org/api_docs/)",
    "5. [Keras Documentation](https://keras.io/api/)",
    "6. [Dash Documentation](https://dash.plotly.com/introduction)"
  ]
}
